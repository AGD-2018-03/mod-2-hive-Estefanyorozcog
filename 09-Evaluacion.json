{
  "kernel": "python",
  "cells": [
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "**Recuerde no agregar o quitar celdas en este notebook, ni modificar su tipo. Si lo hace, el sistema automaticamente lo calificar\u00e1 con cero punto cero (0.0)**"
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "Para resolver los problemas presentados, use el siguiente conjunto de datos. Use [gradetool](gradetool.md) para verificar las respuestas del notebook."
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%run bd.py\n%hive_init"
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%%writefile tbl0.csv\n1,D,4,2016-06-25,a:e:c:d,bb#10:dd#20:cc#40\n2,C,4,2015-05-14,a:c,dd#40:bb#20:cc#10\n3,D,6,2014-12-26,b:d,aa#10:bb#40\n4,D,5,2016-06-25,a:c:e:b:d,bb#40:dd#20:aa#10:cc#30\n5,C,7,2016-05-23,d:e:c,cc#10:aa#20\n6,A,2,2018-06-14,a:d,aa#20\n7,B,3,2014-12-22,a:e:d,cc#20\n8,C,6,2015-08-20,d:a:c:e,cc#10:aa#20\n9,B,3,2017-12-08,b:a:c:e,cc#40:dd#10:aa#30:bb#20\n10,B,7,2015-07-28,c:d:e:a:b,aa#10:dd#40:cc#30"
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%%hive\nDROP TABLE IF EXISTS tbl0;\nCREATE TABLE tbl0 (\n    c1 INT,\n    c2 STRING,\n    c3 INT,\n    c4 DATE,\n    c5 ARRAY<CHAR(1)>, \n    c6 MAP<STRING, INT>\n)\nROW FORMAT DELIMITED \nFIELDS TERMINATED BY ','\nCOLLECTION ITEMS TERMINATED BY ':'\nMAP KEYS TERMINATED BY '#'\nLINES TERMINATED BY '\\n';\n\nLOAD DATA LOCAL INPATH 'tbl0.csv' INTO TABLE tbl0;\n\nSELECT * FROM tbl0;"
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%%writefile tbl1.csv\n1,7,bb,A#0:B#4:C#1:D#3:E#5\n2,13,Cc,A#4:B#1:C#0:D#5:E#2\n3,11,dD,A#5:B#4:C#3:D#1:E#0\n4,3,BB,A#2:B#4:C#3:D#5:E#1\n5,14,cc,A#4:B#0:C#2:D#5:E#3\n6,8,cC,A#4:B#5:C#1:D#2:E#3\n7,2,DD,A#0:B#5:C#2:D#4:E#3\n8,6,dd,A#4:B#2:C#5:D#3:E#0\n9,9,aa,A#1:B#4:C#2:D#5:E#3\n10,4,Bb,A#2:B#3:C#4:D#1:E#0"
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%%hive\nDROP TABLE IF EXISTS tbl1;\nCREATE TABLE tbl1 (\n    c1 INT,\n    c2 INT,\n    c3 STRING,\n    c4 MAP<STRING, INT>\n)\nROW FORMAT DELIMITED \nFIELDS TERMINATED BY ','\nCOLLECTION ITEMS TERMINATED BY ':'\nMAP KEYS TERMINATED BY '#'\nLINES TERMINATED BY '\\n';\n\nLOAD DATA LOCAL INPATH 'tbl1.csv' INTO TABLE tbl1;\n\nSELECT * FROM tbl1;"
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 1\n\nEscriba una consulta que retorne los valores \u00fanicos de la columna `t0.c5` (ordenados). "
    },
    {
      "cell_type": "code",
      "grade": true,
      "test": false,
      "execution_count": 6,
      "points": 5,
      "source": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Query ID = jdvelasq_20181019101119_9fa49fb3-9c81-4f84-8972-7f2bc0b70600\nTotal jobs = 2\nLaunching Job 1 out of 2\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nJob running in-process (local Hadoop)\n2018-10-19 10:11:22,277 Stage-1 map = 100%,  reduce = 100%\nEnded Job = job_local588314225_0001\nLaunching Job 2 out of 2\nNumber of reduce tasks determined at compile time: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nJob running in-process (local Hadoop)\n2018-10-19 10:11:23,928 Stage-2 map = 100%,  reduce = 100%\nEnded Job = job_local1209133375_0002\nMapReduce Jobs Launched: \nStage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nStage-Stage-2:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nTotal MapReduce CPU Time Spent: 0 msec\nOK\na\nb\nc\nd\ne\nTime taken: 3.975 seconds, Fetched: 5 row(s)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 2\n\nRealice una consulta que compute la cantidad de veces que aparece cada valor de la columna `t0.c5`  por a\u00f1o."
    },
    {
      "cell_type": "code",
      "grade": true,
      "test": false,
      "execution_count": 7,
      "points": 5,
      "source": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Query ID = jdvelasq_20181019101125_b32e0af7-0d1e-4908-b1c9-56dee6425045\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nJob running in-process (local Hadoop)\n2018-10-19 10:11:26,657 Stage-1 map = 100%,  reduce = 100%\nEnded Job = job_local1147659857_0003\nMapReduce Jobs Launched: \nStage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nTotal MapReduce CPU Time Spent: 0 msec\nOK\n2014\ta\t1\n2014\tb\t1\n2014\td\t2\n2014\te\t1\n2015\ta\t3\n2015\tb\t1\n2015\tc\t3\n2015\td\t2\n2015\te\t2\n2016\ta\t2\n2016\tb\t1\n2016\tc\t3\n2016\td\t3\n2016\te\t3\n2017\ta\t1\n2017\tb\t1\n2017\tc\t1\n2017\te\t1\n2018\ta\t1\n2018\td\t1\nTime taken: 1.641 seconds, Fetched: 20 row(s)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 3\n\nEscriba una consulta que retorne los elementos de la columna t0.c5 en may\u00fasculas, tal como se muestra a continuaci\u00f3n.\n\nOriginal:\n\n    [\"a\",\"e\",\"c\",\"d\"]\n    [\"a\",\"c\"]\n    [\"b\",\"d\"]\n    [\"a\",\"c\",\"e\",\"b\",\"d\"]\n    [\"d\",\"e\",\"c\"]\n    [\"a\",\"d\"]\n    [\"a\",\"e\",\"d\"]\n    [\"d\",\"a\",\"c\",\"e\"]\n    [\"b\",\"a\",\"c\",\"e\"]\n    [\"c\",\"d\",\"e\",\"a\",\"b\"]\n\nTransformada:\n\n    [\"A\",\"E\",\"C\",\"D\"]\n    [\"A\",\"C\"]\n    [\"B\",\"D\"]\n    [\"A\",\"C\",\"E\",\"B\",\"D\"]\n    [\"D\",\"E\",\"C\"]\n    [\"A\",\"D\"]\n    [\"A\",\"E\",\"D\"]\n    [\"D\",\"A\",\"C\",\"E\"]\n    [\"B\",\"A\",\"C\",\"E\"]\n    [\"C\",\"D\",\"E\",\"A\",\"B\"]"
    },
    {
      "cell_type": "code",
      "grade": true,
      "test": false,
      "execution_count": 8,
      "points": 5,
      "source": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Query ID = jdvelasq_20181019101127_e8d7d8dd-4c2a-4f72-8cf8-8a7f44501351\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nJob running in-process (local Hadoop)\n2018-10-19 10:11:28,926 Stage-1 map = 100%,  reduce = 100%\nEnded Job = job_local94604903_0004\nMapReduce Jobs Launched: \nStage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nTotal MapReduce CPU Time Spent: 0 msec\nOK\n[\"A\",\"E\",\"C\",\"D\"]\n[\"A\",\"C\"]\n[\"B\",\"D\"]\n[\"A\",\"C\",\"E\",\"B\",\"D\"]\n[\"D\",\"E\",\"C\"]\n[\"A\",\"D\"]\n[\"A\",\"E\",\"D\"]\n[\"D\",\"A\",\"C\",\"E\"]\n[\"B\",\"A\",\"C\",\"E\"]\n[\"C\",\"D\",\"E\",\"A\",\"B\"]\nTime taken: 1.633 seconds, Fetched: 10 row(s)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 4\n\nEscriba una consulta que retorne para cada valor \u00fanico de la columna `t0.c2`, los valores correspondientes de la columna `\nt0.c1`. "
    },
    {
      "cell_type": "code",
      "grade": true,
      "test": false,
      "execution_count": 9,
      "points": 5,
      "source": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Query ID = jdvelasq_20181019101129_e05666b9-266f-42f1-b09d-366964b87a97\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nJob running in-process (local Hadoop)\n2018-10-19 10:11:31,461 Stage-1 map = 100%,  reduce = 100%\nEnded Job = job_local251080555_0005\nMapReduce Jobs Launched: \nStage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nTotal MapReduce CPU Time Spent: 0 msec\nOK\nA\t[6]\nB\t[7,9,10]\nC\t[2,5,8]\nD\t[1,3,4]\nTime taken: 1.958 seconds, Fetched: 4 row(s)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 5\n\nEscriba una consulta que para cada valor \u00fanico de la columna `t0.c2,` calcule la suma de todos los valores asociados a las claves en la columna `t0.c6`."
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "%%hive\n-- __begin__\nSELECT \n    c2,\n    sum(value)\nFROM \n    tbl0\nLATERAL VIEW \n    explode(c6) tbl0\nGROUP BY\n    c2;\n-- __end__"
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "# Problema 6\n\nEscriba una consulta que retorne la columna `tbl0.c1` y el valor correspondiente de la columna `tbl1.c4` para la columna `tbl0.c2`."
    },
    {
      "cell_type": "code",
      "grade": true,
      "test": false,
      "execution_count": 11,
      "points": 5,
      "source": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Query ID = jdvelasq_20181019101134_b15c788e-6e1d-4c07-9cde-7037221e348b\nTotal jobs = 1\nSLF4J: Found binding in [jar:file:/Volumes/Data/big-data/hive-3.1.0/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n2018-10-19 10:11:48\tStarting to launch local task to process map join;\tmaximum memory = 239075328\n\n2018-10-19 10:11:48\tEnd of local task; Time Taken: 0.526 sec.\nExecution completed successfully\nMapredLocal task succeeded\nLaunching Job 1 out of 1\nNumber of reduce tasks is set to 0 since there's no reduce operator\nJob running in-process (local Hadoop)\n2018-10-19 10:11:52,838 Stage-3 map = 100%,  reduce = 0%\nEnded Job = job_local1988969047_0007\nMapReduce Jobs Launched: \nStage-Stage-3:  HDFS Read: 0 HDFS Write: 0 SUCCESS\nTotal MapReduce CPU Time Spent: 0 msec\nOK\n1\tD\t3\n2\tC\t0\n3\tD\t1\n4\tD\t5\n5\tC\t2\n6\tA\t4\n7\tB\t5\n8\tC\t5\n9\tB\t4\n10\tB\t3\nTime taken: 18.383 seconds, Fetched: 10 row(s)\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "grade": false,
      "source": "---"
    },
    {
      "cell_type": "code",
      "grade": false,
      "source": "!rm tbl* "
    }
  ]
}